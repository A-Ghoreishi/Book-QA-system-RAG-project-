# ğŸ“š Book-QA System with RAG

This project is an **educational demonstration of Retrieval-Augmented Generation (RAG)**.  
It shows how to build a system that can answer questions about any uploaded PDF book.  
Instead of relying on the language modelâ€™s memory alone, the system retrieves relevant passages from the book and uses them to generate answers with citations.

---

## ğŸ¯ What is RAG?

Large Language Models (LLMs) like GPT are powerful but limited:  
- They donâ€™t automatically know about your specific documents.  
- They can sometimes â€œhallucinateâ€ answers.  

**RAG (Retrieval-Augmented Generation)** fixes this by combining:  
1. **Retrieval** â€“ find the most relevant text passages from a database.  
2. **Generation** â€“ feed those passages plus the question into GPT to write a grounded answer.  

---

## ğŸ—ï¸ How this project works

```

PDF â†’ Chunking â†’ Embeddings â†’ Qdrant Vector DB
â†˜
Retriever â† Streamlit UI â† User Question
â†˜
GPT (o4-mini via MetisAI) â†’ Answer + Sources

````

### Key Steps
- **PDF Parsing (PyPDF2)** â€“ extracts raw text from each page.  
- **Chunking (LangChain)** â€“ splits long text into ~1000-token pieces with overlap.  
- **Embeddings (MetisAI/OpenAI)** â€“ converts chunks into vectors (`text-embedding-3-small`).  
- **Vector Database (Qdrant)** â€“ stores vectors for semantic search.  
- **Retriever (LangChain)** â€“ finds top matching chunks for each question.  
- **Generator (GPT o4-mini)** â€“ produces a concise answer, citing the book.  
- **Web UI (Streamlit)** â€“ simple interface to upload a PDF and ask questions.  

---

## ğŸ› ï¸ Why this approach?

- **RAG instead of fine-tuning** â€“ new books work instantly, no retraining required.  
- **Qdrant** â€“ open-source, optimized for vector search, runs easily in Docker.  
- **LangChain** â€“ simplifies chunking, retrieval, and prompt design.  
- **Streamlit** â€“ provides a fast, interactive web interface.  
- **MetisAI proxy** â€“ enables access to GPT where direct OpenAI API isnâ€™t available.  

---

## âš™ï¸ Setup

### 1. Clone repo
```bash
git clone https://github.com/yourname/Book-QA-system-RAG-project.git
cd Book-QA-system-RAG-project
````

### 2. Virtual environment

```powershell
python -m venv .venv
.venv\Scripts\activate
pip install -r requirements.txt
```

### 3. Configure `.env`

```bash
OPENAI_API_KEY=your_metisai_api_key
OPENAI_BASE_URL=https://api.metisai.ir/openai/v1

EMBEDDING_MODEL=text-embedding-3-small
LLM_MODEL=o4-mini

QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=
QDRANT_COLLECTION=book_chunks
```

### 4. Start Qdrant

```powershell
docker compose -f docker\docker-compose.yml up -d
```

Dashboard: [http://localhost:6333/dashboard](http://localhost:6333/dashboard)

---

## â–¶ï¸ Usage

### Web App

```powershell
streamlit run src/ui_streamlit.py
```

* Upload a PDF
* Ask questions
* See answers + source passages

### CLI (optional)

```powershell
python src/rag_chain.py
```

Ask questions directly in the terminal.

---

## ğŸ“Š Example

```
Question: What is this book about?

ğŸ¤– Answer: This book introduces fundamental concepts in data science and explains how they apply to real-world problems.

ğŸ“š Sources:
- Page 1: "Data science is the discipline that combines statistics..."
- Page 2: "In this book we will explore..."
```

---

## ğŸ—ºï¸ Roadmap

* [ ] Embedding visualization (t-SNE) in Streamlit sidebar
* [ ] Multi-book support
* [ ] Deploy Qdrant + Streamlit together with Docker Compose
* [ ] Option to use cloud-hosted Qdrant

---

## ğŸ“œ License

MIT License â€“ free to use and adapt for educational purposes.

```
```
